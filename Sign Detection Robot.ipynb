{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob as glob\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('/Users/eisaadil/.local/lib/python3.6/site-packages/tensorflow/models/research/object_detection') # ~/tensorflow/models/research/object_detection\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import socket\n",
    "import time\n",
    "\n",
    "MODEL_NAME = 'ssd'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
    "MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "PATH_TO_CKPT = os.path.join(MODEL_PATH,'frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('scripts', 'label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 78\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "        \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_ip_address = \"192.168.1.1\"\n",
    "robot_port = 2001\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.connect((robot_ip_address, robot_port))\n",
    "\n",
    "def left(speed):\n",
    "    s.send(bytes([115,speed,0,0]))\n",
    "    s.send(bytes([5])) #STOP\n",
    "    time.sleep(0.7)\n",
    "    s.send(bytes([0])) #LEFT\n",
    "    print(\"Turn Left\")\n",
    "\n",
    "def right(speed):\n",
    "    s.send(bytes([115,speed,0,0]))\n",
    "    s.send(bytes([5])) #STOP\n",
    "    time.sleep(0.7)\n",
    "    s.send(bytes([2])) #LEFT\n",
    "    time.sleep(0.7)\n",
    "    forward(speed)\n",
    "    print(\"Turn Right\")\n",
    "    \n",
    "def stop():\n",
    "    print(\"Stop\")\n",
    "    s.send(bytes([5]))\n",
    "    \n",
    "def sixty(speed):\n",
    "    print(\"60km/h\")\n",
    "    s.send(bytes([115,speed,0,0]))\n",
    "    \n",
    "def forty(speed):\n",
    "    print(\"40km/h\")\n",
    "    s.send(bytes([115,speed,0,0]))    \n",
    "    \n",
    "def forward(speed):\n",
    "    s.send(bytes([115,speed,0,0]))\n",
    "    s.send(bytes([1]))\n",
    "    print(\"Go Forward\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go Forward\n",
      "--- 8.798331022262573 seconds ---\n",
      "--- 0.22805118560791016 seconds ---\n",
      "--- 0.2725520133972168 seconds ---\n",
      "--- 0.21209979057312012 seconds ---\n",
      "--- 0.2305006980895996 seconds ---\n",
      "--- 0.2286982536315918 seconds ---\n",
      "--- 0.2112729549407959 seconds ---\n",
      "--- 0.21019792556762695 seconds ---\n",
      "--- 0.21388006210327148 seconds ---\n",
      "--- 0.21047592163085938 seconds ---\n",
      "--- 0.22667694091796875 seconds ---\n",
      "--- 0.2122328281402588 seconds ---\n",
      "--- 0.21681427955627441 seconds ---\n",
      "--- 0.2140350341796875 seconds ---\n",
      "--- 0.21024298667907715 seconds ---\n",
      "--- 0.21548199653625488 seconds ---\n",
      "--- 0.22582769393920898 seconds ---\n",
      "--- 0.20891904830932617 seconds ---\n",
      "--- 0.20051026344299316 seconds ---\n",
      "--- 0.218214750289917 seconds ---\n",
      "Stop\n",
      "--- 0.20381617546081543 seconds ---\n",
      "Stop\n",
      "--- 0.22373175621032715 seconds ---\n",
      "Stop\n",
      "--- 0.201859712600708 seconds ---\n",
      "Stop\n",
      "--- 0.21648383140563965 seconds ---\n",
      "Stop\n",
      "--- 0.24512124061584473 seconds ---\n",
      "Stop\n",
      "--- 0.2051389217376709 seconds ---\n",
      "--- 0.21579384803771973 seconds ---\n",
      "--- 0.2147071361541748 seconds ---\n",
      "--- 0.21781611442565918 seconds ---\n",
      "--- 0.2146599292755127 seconds ---\n",
      "--- 0.20899415016174316 seconds ---\n",
      "--- 0.20990419387817383 seconds ---\n",
      "--- 0.22128605842590332 seconds ---\n",
      "--- 0.20663690567016602 seconds ---\n",
      "--- 0.23152899742126465 seconds ---\n",
      "--- 0.20712661743164062 seconds ---\n",
      "--- 0.2142939567565918 seconds ---\n",
      "--- 0.22074604034423828 seconds ---\n",
      "--- 0.2115318775177002 seconds ---\n",
      "--- 0.2141880989074707 seconds ---\n",
      "--- 0.2089710235595703 seconds ---\n",
      "--- 0.23296213150024414 seconds ---\n",
      "--- 0.21103477478027344 seconds ---\n",
      "--- 0.2351980209350586 seconds ---\n",
      "--- 0.20375680923461914 seconds ---\n",
      "--- 0.22046899795532227 seconds ---\n",
      "Stop\n",
      "--- 0.23411202430725098 seconds ---\n",
      "Go Forward\n",
      "--- 0.21213102340698242 seconds ---\n",
      "--- 0.21355104446411133 seconds ---\n",
      "--- 0.2177109718322754 seconds ---\n",
      "--- 0.22232818603515625 seconds ---\n",
      "--- 0.21146798133850098 seconds ---\n",
      "--- 0.21074604988098145 seconds ---\n",
      "--- 0.20376801490783691 seconds ---\n",
      "--- 0.21716094017028809 seconds ---\n",
      "--- 0.21564316749572754 seconds ---\n",
      "--- 0.23015928268432617 seconds ---\n",
      "--- 0.21648597717285156 seconds ---\n",
      "--- 0.2215862274169922 seconds ---\n",
      "--- 0.21472883224487305 seconds ---\n",
      "Turn Left\n",
      "--- 0.9202442169189453 seconds ---\n",
      "Turn Left\n",
      "--- 0.945065975189209 seconds ---\n",
      "Turn Left\n",
      "--- 0.9192860126495361 seconds ---\n",
      "--- 0.2536489963531494 seconds ---\n",
      "Turn Left\n",
      "--- 0.927764892578125 seconds ---\n",
      "Turn Left\n",
      "--- 0.9214520454406738 seconds ---\n",
      "Turn Left\n",
      "--- 0.9101927280426025 seconds ---\n",
      "--- 0.2065296173095703 seconds ---\n",
      "--- 0.22199392318725586 seconds ---\n",
      "--- 0.21267366409301758 seconds ---\n",
      "--- 0.21310091018676758 seconds ---\n",
      "--- 0.2137758731842041 seconds ---\n",
      "--- 0.21129488945007324 seconds ---\n",
      "--- 0.21426892280578613 seconds ---\n",
      "--- 0.21457982063293457 seconds ---\n",
      "--- 0.20955705642700195 seconds ---\n",
      "--- 0.21108698844909668 seconds ---\n",
      "--- 0.21615910530090332 seconds ---\n",
      "--- 0.206801176071167 seconds ---\n",
      "--- 0.21446514129638672 seconds ---\n",
      "--- 0.21078705787658691 seconds ---\n",
      "--- 0.2186570167541504 seconds ---\n",
      "--- 0.20810890197753906 seconds ---\n",
      "--- 0.22493410110473633 seconds ---\n",
      "--- 0.20536088943481445 seconds ---\n",
      "--- 0.22383904457092285 seconds ---\n",
      "--- 0.2063608169555664 seconds ---\n",
      "--- 0.21683812141418457 seconds ---\n",
      "--- 0.20757818222045898 seconds ---\n",
      "--- 0.21286225318908691 seconds ---\n",
      "--- 0.21935200691223145 seconds ---\n",
      "--- 0.24712181091308594 seconds ---\n",
      "--- 0.21501898765563965 seconds ---\n",
      "--- 0.2039659023284912 seconds ---\n",
      "--- 0.21172666549682617 seconds ---\n",
      "--- 0.20330500602722168 seconds ---\n",
      "--- 0.20360112190246582 seconds ---\n",
      "--- 0.2031407356262207 seconds ---\n",
      "--- 0.22208476066589355 seconds ---\n",
      "--- 0.20393085479736328 seconds ---\n",
      "--- 0.21957087516784668 seconds ---\n",
      "--- 0.24879002571105957 seconds ---\n",
      "--- 0.20522379875183105 seconds ---\n",
      "--- 0.21616196632385254 seconds ---\n",
      "--- 0.2025890350341797 seconds ---\n",
      "--- 0.2078380584716797 seconds ---\n",
      "--- 0.20411086082458496 seconds ---\n",
      "--- 0.21872210502624512 seconds ---\n",
      "--- 0.2035839557647705 seconds ---\n",
      "--- 30.286680221557617 seconds ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1968ad8196ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_detections:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections], feed_dict = {\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mimage_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_np_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m               })\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"http://192.168.1.1:8080/?action=stream\")\n",
    "IMAGE_SIZE = (20, 20)\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        if (cap.isOpened()== False): \n",
    "              print(\"Error opening video stream or file\")\n",
    "        forward(60)     \n",
    "        ret = True\n",
    "        while (ret):\n",
    "            start_time = time.time()\n",
    "            ret, image_np = cap.read() \n",
    "\n",
    "            # Image Shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis = 0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections], feed_dict = {\n",
    "                image_tensor: image_np_expanded\n",
    "              })\n",
    "            \n",
    "            if scores[0][0]>0.5:\n",
    "                if (classes[0][0]==15): #LEFT\n",
    "                    left(150)\n",
    "                elif (classes[0][0]==40): #RIGHT\n",
    "                    right(150)\n",
    "                elif (classes[0][0]==76): #STOP\n",
    "                    stop()\n",
    "                elif (classes[0][0]==16): #60 SPEED\n",
    "                    sixty(100)\n",
    "                elif (classes[0][0]==67): #40 SPEED (DEFAULT) \n",
    "                    forty(60)\n",
    "                elif (classes[0][0]==36):   \n",
    "                    forward(60)  \n",
    "            \n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              np.squeeze(boxes),\n",
    "              np.squeeze(classes).astype(np.int32),\n",
    "              np.squeeze(scores),\n",
    "              category_index,\n",
    "              use_normalized_coordinates = True,\n",
    "              line_thickness = 8)\n",
    "            \n",
    "#             plt.figure(figsize = IMAGE_SIZE)\n",
    "#             plt.imshow(image_np)\n",
    "            cv2.imshow('image',cv2.resize(image_np,(1280,960)))\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixty(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forty(60)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "IMAGE_SIZE = (20, 20)\n",
    "\n",
    "#Running the tensorflow session\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        if (cap.isOpened()== False): \n",
    "              print(\"Error opening video stream or file\")\n",
    "        ret = True\n",
    "        while (ret):\n",
    "            ret, image_np = cap.read() \n",
    "\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis = 0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "            # Each score represent how level of confidence for each of the objects\n",
    "            #Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections], feed_dict = {\n",
    "                image_tensor: image_np_expanded\n",
    "              })# Visualization of the results of a detection.\n",
    "            \n",
    "            if scores[0][0]>0.8:\n",
    "                if (classes[0][0]==15):\n",
    "                    print(\"Turn Left\")\n",
    "                elif (classes[0][0]==40):    \n",
    "                    print(\"Turn Right\")\n",
    "                elif (classes[0][0]==76):    \n",
    "                    print(\"Stop\")\n",
    "                elif (classes[0][0]==16):    \n",
    "                    print(\"60km/h\")\n",
    "                elif (classes[0][0]==67):    \n",
    "                    print(\"40km/h\")    \n",
    "                elif (classes[0][0]==36):   \n",
    "                    print(\"Go Forward\")\n",
    "            \n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              np.squeeze(boxes),\n",
    "              np.squeeze(classes).astype(np.int32),\n",
    "              np.squeeze(scores),\n",
    "              category_index,\n",
    "              use_normalized_coordinates = True,\n",
    "              line_thickness = 8)\n",
    "            \n",
    "            plt.figure(figsize = IMAGE_SIZE)\n",
    "            plt.imshow(image_np)\n",
    "            \n",
    "            cv2.imshow('image',cv2.resize(image_np,(1280,960)))\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpeg'))\n",
    "IMAGE_SIZE = (20, 20)\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            \n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            width, height = image.size\n",
    "            print(\"score: \", scores[0][0])\n",
    "#             box = boxes[0][0]\n",
    "#             print(box)\n",
    "#             ymin = (box[0] * height).astype(int)\n",
    "#             xmin = (box[1] * width).astype(int)\n",
    "#             ymax = (box[2] * height).astype(int)\n",
    "#             xmax = (box[3] * width).astype(int)\n",
    "#             print((ymax-ymin)*(xmax-xmin))\n",
    "#             new_im = image_np[ymin:ymin+ymax,xmin:xmin+xmax]\n",
    "            \n",
    "            plt.imshow(new_im)\n",
    "            \n",
    "            #[ymin, xmin, ymax, xmax]\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=6)\n",
    "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image_np)\n",
    "            \n",
    "            #15 is turn left\n",
    "            #40 is turn right\n",
    "            #76 is stop\n",
    "            #37 is 20km/h\n",
    "            #67 is 40km/h\n",
    "            \n",
    "            if scores[0][0]>0.8:\n",
    "                if (classes[0][0]==15):\n",
    "                    print(\"Turn Left\")\n",
    "                elif (classes[0][0]==40):    \n",
    "                    print(\"Turn Right\")\n",
    "                elif (classes[0][0]==76):    \n",
    "                    print(\"Stop\")\n",
    "                elif (classes[0][0]==37):    \n",
    "                    print(\"20km/h\")\n",
    "                elif (classes[0][0]==67):    \n",
    "                    print(\"40km/h\")    \n",
    "                    \n",
    "#             print(category_index)\n",
    "#             print(classes)\n",
    "#             print(scores)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
